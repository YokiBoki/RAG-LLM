<template>
  <div class="ai-practice-container">
    <!-- å·¦ä¾§å†å²å¯¹è¯è®°å½• -->
    <div class="history-panel">
      <div class="new-chat-container">
        <button class="new-chat-btn" @click="newConversation">
          æ–°å»ºå¯¹è¯
          <el-icon class="plus-icon">
            <Plus/>
          </el-icon>
        </button>
      </div>
      <ul class="history-list">
        <li v-for="(item, index) in historyList" :key="index" @click="selectConversation(index)"
            :class="{ active: currentConversationIndex === index }">
          {{ item.title }}
        </li>
      </ul>
    </div>

    <!-- å³ä¾§å¯¹è¯é¡µé¢ -->
    <div class="chat-wrapper">
      <div class="chat-panel">
        <!-- ä¸ŠåŠéƒ¨åˆ†èŠå¤©ç•Œé¢ -->
        <div class="chat-messages" ref="chatMessagesRef">
          <div v-for="(message, index) in currentConversation.messages" :key="index" :class="['message', message.role]">
            <div class="avatar">
              <div v-if="message.role !== 'user'" class="ai-avatar">
                <img src="@/assets/images/robot.png" alt="AI Avatar">
              </div>
              <div v-else>
                <img src="@/assets/images/user.png" alt="Me">
              </div>
            </div>
            <div class="content">
              {{ message.content }}
              <span v-if="message.role === 'assistant'" class="play-icon" @click="playVoice(message.content)">ğŸ”Š</span>
            </div>
          </div>
        </div>

        <!-- è¾“å…¥æ¡† -->
        <div class="input-area">
          <div class="input-wrapper">
            <el-icon class="input-icon link-icon">
              <Link/>
            </el-icon>
            <input
                v-model="userInput"
                @keyup.enter="sendMessage"
                placeholder="è¾“å…¥æ¶ˆæ¯ï¼ŒæŒ‰å›è½¦å‘é€..."
                type="text"
                :disabled="isInputDisabled"
            >
            <div class="button-group">
              <div class="audio-wave" v-if="isRecording" @click="finishRecording">
                <span v-for="n in 4" :key="n" :style="{ animationDelay: `${n * 0.2}s` }"></span>
              </div>
              <el-icon v-else class="input-icon microphone-icon" @click="toggleRecording">
                <Microphone/>
              </el-icon>
              <div class="separator"></div>
              <el-popover
                  placement="top"
                  :width="200"
                  trigger="hover"
                  :disabled="!!userInput.trim()"
              >
                <template #reference>
                  <el-button
                      class="send-button"
                      circle
                      @click="sendMessage"
                      :disabled="!userInput.trim()"
                  >
                    <el-icon>
                      <Top/>
                    </el-icon>
                  </el-button>
                </template>
                <span>è¯·æ–‡å­—/å½•éŸ³/ä¸Šä¼ è¯­éŸ³å›å¤</span>
              </el-popover>
            </div>
          </div>
        </div>

        <div class="disclaimer">
          æœåŠ¡ç”Ÿæˆçš„æ‰€æœ‰å†…å®¹å‡ç”±AIç”Ÿæˆ
        </div>
      </div>
    </div>
  </div>
</template>

<script setup>
import {ref, computed, nextTick, onMounted, onUnmounted} from 'vue';
import {Link, Microphone} from '@element-plus/icons-vue';
import {ElMessage} from 'element-plus';
// import AudioBase from "@/components/AudioBase.vue";
import {get, post} from '@/utils/request'
import {API} from '@/api/config'
import '@/assets/chatpage.css'

const playingText = ref('');
const ttsCache = new Map();
const playVoice = async (text) => {

  if (ttsCache.has(text)) {
    const cachedUrl = ttsCache.get(text);
    new Audio(cachedUrl).play();
    return;
  }

  try {
    playingText.value = text;  // æ ‡è®°ä¸ºå½“å‰æ’­æ”¾ä¸­
    const response = await fetch(`http://localhost:8000/api/tts?text=${encodeURIComponent(text)}&rate=-10%`);
    const audioBlob = await response.blob();
    const audioUrl = URL.createObjectURL(audioBlob);
    const audio = new Audio(audioUrl);
    audio.play();
    audio.onended = () => playingText.value = '';
  } catch (error) {
    ElMessage.error('æ’­æ”¾å¤±è´¥ï¼Œè¯·ç¨åé‡è¯•');
    playingText.value = '';
  }
};

const historyList = ref([
  {
    title: 'å¥åº·çŸ¥è¯†å’¨è¯¢',
    messages: [
      {role: 'assistant', content: 'æ‚¨å¥½ï¼æˆ‘æ˜¯æ‚¨çš„å¥åº·åŠ©æ‰‹ï¼Œä½ éœ€è¦å’¨è¯¢ä»€ä¹ˆå¥åº·é—®é¢˜ï¼Ÿ'},
      {role: 'user', content: 'æˆ‘æœ€è¿‘æ€»æ˜¯æ„Ÿåˆ°ç–²åŠ³ï¼Œè¯·é—®è¿™æ˜¯æ€ä¹ˆå›äº‹ï¼Ÿ'},
      {
        role: 'assistant',
        content: 'åˆ«æ‹…å¿ƒï¼è®©æˆ‘æ¥å¸®æ‚¨åˆ†æä¸€ä¸‹ã€‚ç–²åŠ³å¯èƒ½æ˜¯ç”±äºå¤šç§åŸå› å¼•èµ·çš„ï¼ŒåŒ…æ‹¬ç¡çœ ä¸è¶³ã€è¥å…»ä¸è‰¯ã€ç¼ºä¹è¿åŠ¨ç­‰ã€‚å»ºè®®æ‚¨ä¿æŒè‰¯å¥½çš„ä½œæ¯ä¹ æƒ¯ï¼Œå‡è¡¡é¥®é£Ÿï¼Œé€‚é‡è¿åŠ¨ã€‚å¦‚æœç—‡çŠ¶æŒç»­ï¼Œå»ºè®®å’¨è¯¢åŒ»ç”Ÿè¿›è¡Œè¿›ä¸€æ­¥æ£€æŸ¥ã€‚'
      }
    ]
  },

  
]);

const currentConversationIndex = ref(0);
const userInput = ref('');
const isListening = ref(false);
const chatMessagesRef = ref(null);
const isRecording = ref(false);
let mediaRecorder = null;
let audioChunks = [];
let recognition = null;
const mediaStream = ref(null);
const isInputDisabled = ref(false);

const currentConversation = computed(() => historyList.value[currentConversationIndex.value]);

const selectConversation = (index) => {
  currentConversationIndex.value = index;
  nextTick(() => {
    scrollToBottom();
  });
};

const newConversation = () => {
  historyList.value.unshift({
    title: 'æ–°å¯¹è¯',
    // å®é™…ä¸Šè¿™é‡Œè¦å’Œåç«¯äº¤äº’çš„è¯ï¼Œmessages æœ€å¥½ç”¨ map æ ¼å¼ï¼Œkey æ˜¯å¯¹åº”çš„ idï¼Œè¿™æ ·æ–¹ä¾¿åç«¯æ ¹æ® id æ¥æ“ä½œæ¶ˆæ¯
    messages: [{
      role: 'assistant',
      content: 'æ‚¨å¥½ï¼æˆ‘æ˜¯æ‚¨çš„å¥åº·åŠ©æ‰‹ï¼Œä½ éœ€è¦å’¨è¯¢ä»€ä¹ˆå¥åº·é—®é¢˜ï¼Ÿ',
    }]
  });
  currentConversationIndex.value = 0;
};

const sendMessage = async () => {
  if (userInput.value.trim()) {
    // æ·»åŠ ç”¨æˆ·æ¶ˆæ¯
    currentConversation.value.messages.push({role: 'user', content: userInput.value});
    const prompt = userInput.value;
    userInput.value = '';
    nextTick(() => {
      scrollToBottom();
    });

    const loadingMessage = ref({
      role: 'assistant',
      content: 'æ­£åœ¨æ€è€ƒ...',
      loading: true // æ ‡è®°ä¸ºåŠ è½½çŠ¶æ€
    });
    currentConversation.value.messages.push(loadingMessage.value);
    nextTick(() => {
      scrollToBottom();
    });

    // è·å–AIå›å¤
    try {
      const res = await get(API.GENERATE, {prompt: prompt});
      if (res.code == 100) {
        // æ›´æ–°åŠ è½½ä¸­çš„æ¶ˆæ¯ä¸ºå®é™…å›å¤
        loadingMessage.value.content = res.data;
        loadingMessage.value.loading = false; // æ›´æ–°ä¸ºéåŠ è½½çŠ¶æ€
        nextTick(() => {
          scrollToBottom();
        });
      } else {
        ElMessage.error(res.msg);
        loadingMessage.value.content = 'è·å–å›å¤å¤±è´¥ï¼Œè¯·ç¨åé‡è¯•';
        loadingMessage.value.loading = false;
        nextTick(() => {
          scrollToBottom();
        });
      }
    } catch (error) {
      console.error('sendMessage error', error);
      ElMessage.error('è·å–å›å¤å¤±è´¥ï¼Œè¯·ç¨åé‡è¯•');
      loadingMessage.value.content = 'è·å–å›å¤å¤±è´¥ï¼Œè¯·ç¨åé‡è¯•';
      loadingMessage.value.loading = false;
      nextTick(() => {
        scrollToBottom();
      });
    }
  }
};

const finishRecording = () => {
    stopVoiceRecognition();
    isInputDisabled.value = false;
  
};

const stopVoiceRecognition = () => {
  if (recognition) {
    recognition.stop(); // è¿™ä¼šè‡ªåŠ¨è§¦å‘ onend äº‹ä»¶
  }
};

const sendAudioMessage = (audioBlob) => {
  const audioUrl = URL.createObjectURL(audioBlob);
  currentConversation.value.messages.push({
    role: 'user',
    content: 'å‘é€äº†ä¸€æ¡è¯­éŸ³æ¶ˆæ¯',
    audioUrl: audioUrl
  });
  nextTick(() => {
    scrollToBottom();
  });

};

const toggleRecording = () => {
  if (!isRecording.value) {
    startVoiceRecognition();
  } else {
    stopVoiceRecognition();
  }
  isRecording.value = !isRecording.value;
};

const startVoiceRecognition = () => {
  recognition = new (window.SpeechRecognition || window.webkitSpeechRecognition)();
  recognition.lang = 'zh-CN';
  recognition.continuous = false;
  recognition.interimResults = false;

  recognition.onstart = () => {
    isInputDisabled.value = true; // è¯­éŸ³è¾“å…¥æ—¶ç¦ç”¨æ–‡æœ¬æ¡†
    isRecording.value = true;
  };

  recognition.onresult = (event) => {
    const transcript = event.results[0][0].transcript;
    userInput.value = transcript;
    sendMessage();
  };

  recognition.onerror = () => {
    isRecording.value = false;
  };

  recognition.onend = () => {
    isRecording.value = false;
    isInputDisabled.value = false; // æ¢å¤æ–‡æœ¬æ¡†
  };

  recognition.start();
};


const stopMediaStream = () => {
  if (mediaStream.value) {
    mediaStream.value.getTracks().forEach(track => track.stop());
    mediaStream.value = null;
  }
};

const scrollToBottom = () => {
  const chatMessages = chatMessagesRef.value;
  chatMessages.scrollTop = chatMessages.scrollHeight;
};

onMounted(() => {
});

onUnmounted(() => {
  finishRecording();
  stopMediaStream();
});
</script>
